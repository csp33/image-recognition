Using TensorFlow backend.
50000 train samples
10000 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_1 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 15, 15, 256)       295168
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 13, 13, 256)       590080
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0
_________________________________________________________________
dropout_2 (Dropout)          (None, 6, 6, 256)         0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 6, 6, 512)         1180160
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 512)         2359808
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 512)         0
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              2098176
_________________________________________________________________
dropout_4 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_2 (Dense)              (None, 100)               102500
=================================================================
Total params: 6,777,060
Trainable params: 6,777,060
Non-trainable params: 0
_________________________________________________________________
Epoch 1/139
1562/1562 [==============================] - 133s 85ms/step - loss: 4.0857 - acc: 0.0800 - val_loss: 3.5779 - val_acc: 0.1663
Epoch 2/139
1562/1562 [==============================] - 123s 79ms/step - loss: 3.6691 - acc: 0.1501 - val_loss: 3.2172 - val_acc: 0.2310
Epoch 3/139
1562/1562 [==============================] - 122s 78ms/step - loss: 3.4617 - acc: 0.1863 - val_loss: 3.0715 - val_acc: 0.2531
Epoch 4/139
1562/1562 [==============================] - 122s 78ms/step - loss: 3.3186 - acc: 0.2121 - val_loss: 2.9516 - val_acc: 0.2832
Epoch 5/139
1562/1562 [==============================] - 122s 78ms/step - loss: 3.1971 - acc: 0.2358 - val_loss: 2.6891 - val_acc: 0.3306
Epoch 6/139
1562/1562 [==============================] - 122s 78ms/step - loss: 3.1066 - acc: 0.2573 - val_loss: 2.5953 - val_acc: 0.3553
Epoch 7/139
1562/1562 [==============================] - 122s 78ms/step - loss: 3.0109 - acc: 0.2742 - val_loss: 2.4910 - val_acc: 0.3739
Epoch 8/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.9335 - acc: 0.2918 - val_loss: 2.4527 - val_acc: 0.3801
Epoch 9/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.8653 - acc: 0.3059 - val_loss: 2.3838 - val_acc: 0.3961
Epoch 10/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.7925 - acc: 0.3192 - val_loss: 2.3667 - val_acc: 0.3994
Epoch 11/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.7420 - acc: 0.3287 - val_loss: 2.2769 - val_acc: 0.4194
Epoch 12/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.6732 - acc: 0.3452 - val_loss: 2.3406 - val_acc: 0.4072
Epoch 13/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.6266 - acc: 0.3544 - val_loss: 2.1859 - val_acc: 0.4421
Epoch 14/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.5765 - acc: 0.3628 - val_loss: 2.1727 - val_acc: 0.4399
Epoch 15/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.5349 - acc: 0.3732 - val_loss: 2.1648 - val_acc: 0.4449
Epoch 16/139
1562/1562 [==============================] - 123s 78ms/step - loss: 2.4808 - acc: 0.3837 - val_loss: 2.1892 - val_acc: 0.4385
Epoch 17/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.4493 - acc: 0.3923 - val_loss: 2.0869 - val_acc: 0.4590
Epoch 18/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.4005 - acc: 0.4038 - val_loss: 2.0599 - val_acc: 0.4674
Epoch 19/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.3624 - acc: 0.4089 - val_loss: 2.0798 - val_acc: 0.4629
Epoch 20/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.3358 - acc: 0.4169 - val_loss: 1.9897 - val_acc: 0.4813
Epoch 21/139
1562/1562 [==============================] - 123s 78ms/step - loss: 2.3024 - acc: 0.4213 - val_loss: 2.0132 - val_acc: 0.4756
Epoch 22/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.2729 - acc: 0.4297 - val_loss: 2.0060 - val_acc: 0.4804
Epoch 23/139
1562/1562 [==============================] - 123s 78ms/step - loss: 2.2467 - acc: 0.4365 - val_loss: 1.9364 - val_acc: 0.4913
Epoch 24/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.2234 - acc: 0.4381 - val_loss: 1.9317 - val_acc: 0.4982
Epoch 25/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.2041 - acc: 0.4451 - val_loss: 1.9475 - val_acc: 0.4891
Epoch 26/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.1911 - acc: 0.4467 - val_loss: 1.8916 - val_acc: 0.4999
Epoch 27/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.1575 - acc: 0.4545 - val_loss: 1.8448 - val_acc: 0.5140
Epoch 28/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.1427 - acc: 0.4561 - val_loss: 1.9161 - val_acc: 0.5007
Epoch 29/139
1562/1562 [==============================] - 123s 78ms/step - loss: 2.1272 - acc: 0.4603 - val_loss: 1.8582 - val_acc: 0.5089
Epoch 30/139
1562/1562 [==============================] - 123s 78ms/step - loss: 2.1057 - acc: 0.4648 - val_loss: 1.8436 - val_acc: 0.5147
Epoch 31/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0924 - acc: 0.4698 - val_loss: 1.8173 - val_acc: 0.5244
Epoch 32/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0725 - acc: 0.4727 - val_loss: 1.7905 - val_acc: 0.5245
Epoch 33/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0536 - acc: 0.4769 - val_loss: 1.8206 - val_acc: 0.5155
Epoch 34/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0532 - acc: 0.4785 - val_loss: 1.7807 - val_acc: 0.5264
Epoch 35/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0234 - acc: 0.4828 - val_loss: 1.8441 - val_acc: 0.5220
Epoch 36/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0271 - acc: 0.4839 - val_loss: 1.8041 - val_acc: 0.5188
Epoch 37/139
1562/1562 [==============================] - 122s 78ms/step - loss: 2.0038 - acc: 0.4879 - val_loss: 1.8558 - val_acc: 0.5170
Epoch 38/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9966 - acc: 0.4930 - val_loss: 1.8050 - val_acc: 0.5272
Epoch 39/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9920 - acc: 0.4928 - val_loss: 1.7545 - val_acc: 0.5368
Epoch 40/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9698 - acc: 0.4976 - val_loss: 1.7404 - val_acc: 0.5396
Epoch 41/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9568 - acc: 0.5022 - val_loss: 1.7852 - val_acc: 0.5324
Epoch 42/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9518 - acc: 0.5025 - val_loss: 1.7989 - val_acc: 0.5331
Epoch 43/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9446 - acc: 0.5039 - val_loss: 1.7512 - val_acc: 0.5424
Epoch 44/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.9237 - acc: 0.5082 - val_loss: 1.7768 - val_acc: 0.5351
Epoch 45/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.9248 - acc: 0.5112 - val_loss: 1.8033 - val_acc: 0.5311
Epoch 46/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.9141 - acc: 0.5105 - val_loss: 1.7501 - val_acc: 0.5360
Epoch 47/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8961 - acc: 0.5120 - val_loss: 1.6837 - val_acc: 0.5589
Epoch 48/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8940 - acc: 0.5146 - val_loss: 1.6992 - val_acc: 0.5588
Epoch 49/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.8822 - acc: 0.5199 - val_loss: 1.7209 - val_acc: 0.5494
Epoch 50/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8823 - acc: 0.5215 - val_loss: 1.7058 - val_acc: 0.5530
Epoch 51/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8635 - acc: 0.5259 - val_loss: 1.7079 - val_acc: 0.5599
Epoch 52/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8575 - acc: 0.5278 - val_loss: 1.7180 - val_acc: 0.5552
Epoch 53/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8448 - acc: 0.5297 - val_loss: 1.6927 - val_acc: 0.5593
Epoch 54/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.8395 - acc: 0.5310 - val_loss: 1.7072 - val_acc: 0.5510
Epoch 55/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8374 - acc: 0.5320 - val_loss: 1.7100 - val_acc: 0.5559
Epoch 56/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8186 - acc: 0.5332 - val_loss: 1.7079 - val_acc: 0.5541
Epoch 57/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.8204 - acc: 0.5308 - val_loss: 1.7053 - val_acc: 0.5536
Epoch 58/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8026 - acc: 0.5408 - val_loss: 1.6997 - val_acc: 0.5595
Epoch 59/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8003 - acc: 0.5397 - val_loss: 1.6808 - val_acc: 0.5627
Epoch 60/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.8042 - acc: 0.5386 - val_loss: 1.6865 - val_acc: 0.5623
Epoch 61/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.7944 - acc: 0.5405 - val_loss: 1.7396 - val_acc: 0.5552
Epoch 62/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7932 - acc: 0.5407 - val_loss: 1.7296 - val_acc: 0.5583
Epoch 63/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7704 - acc: 0.5444 - val_loss: 1.6779 - val_acc: 0.5678
Epoch 64/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7705 - acc: 0.5501 - val_loss: 1.7219 - val_acc: 0.5639
Epoch 65/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7767 - acc: 0.5452 - val_loss: 1.6659 - val_acc: 0.5752
Epoch 66/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.7523 - acc: 0.5500 - val_loss: 1.6908 - val_acc: 0.5633
Epoch 67/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7620 - acc: 0.5502 - val_loss: 1.7186 - val_acc: 0.5542
Epoch 68/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7357 - acc: 0.5552 - val_loss: 1.6972 - val_acc: 0.5619
Epoch 69/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7395 - acc: 0.5559 - val_loss: 1.6719 - val_acc: 0.5627
Epoch 70/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7361 - acc: 0.5545 - val_loss: 1.6657 - val_acc: 0.5737
Epoch 71/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.7195 - acc: 0.5593 - val_loss: 1.6808 - val_acc: 0.5657
Epoch 72/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.7229 - acc: 0.5605 - val_loss: 1.6486 - val_acc: 0.5745
Epoch 73/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7249 - acc: 0.5573 - val_loss: 1.6485 - val_acc: 0.5748
Epoch 74/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7184 - acc: 0.5613 - val_loss: 1.6396 - val_acc: 0.5783
Epoch 75/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7094 - acc: 0.5630 - val_loss: 1.6685 - val_acc: 0.5734
Epoch 76/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.7160 - acc: 0.5621 - val_loss: 1.6620 - val_acc: 0.5701
Epoch 77/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6964 - acc: 0.5656 - val_loss: 1.6534 - val_acc: 0.5778
Epoch 78/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.7015 - acc: 0.5675 - val_loss: 1.6686 - val_acc: 0.5806
Epoch 79/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6863 - acc: 0.5684 - val_loss: 1.6318 - val_acc: 0.5809
Epoch 80/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6852 - acc: 0.5676 - val_loss: 1.6823 - val_acc: 0.5755
Epoch 81/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6899 - acc: 0.5677 - val_loss: 1.6767 - val_acc: 0.5763
Epoch 82/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6782 - acc: 0.5721 - val_loss: 1.6269 - val_acc: 0.5880
Epoch 83/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6947 - acc: 0.5677 - val_loss: 1.6830 - val_acc: 0.5716
Epoch 84/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6725 - acc: 0.5749 - val_loss: 1.6571 - val_acc: 0.5751
Epoch 85/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6720 - acc: 0.5736 - val_loss: 1.7166 - val_acc: 0.5653
Epoch 86/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6780 - acc: 0.5713 - val_loss: 1.6448 - val_acc: 0.5830
Epoch 87/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6665 - acc: 0.5760 - val_loss: 1.6897 - val_acc: 0.5818
Epoch 88/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6584 - acc: 0.5755 - val_loss: 1.7237 - val_acc: 0.5670
Epoch 89/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6699 - acc: 0.5763 - val_loss: 1.6299 - val_acc: 0.5898
Epoch 90/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6500 - acc: 0.5783 - val_loss: 1.6617 - val_acc: 0.5826
Epoch 91/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6405 - acc: 0.5829 - val_loss: 1.6796 - val_acc: 0.5820
Epoch 92/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6519 - acc: 0.5806 - val_loss: 1.6912 - val_acc: 0.5760
Epoch 93/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6388 - acc: 0.5829 - val_loss: 1.6993 - val_acc: 0.5735
Epoch 94/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6463 - acc: 0.5819 - val_loss: 1.6145 - val_acc: 0.5905
Epoch 95/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6426 - acc: 0.5827 - val_loss: 1.6933 - val_acc: 0.5713
Epoch 96/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6301 - acc: 0.5845 - val_loss: 1.6438 - val_acc: 0.5834
Epoch 97/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6411 - acc: 0.5842 - val_loss: 1.6395 - val_acc: 0.5890
Epoch 98/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6412 - acc: 0.5837 - val_loss: 1.6614 - val_acc: 0.5863
Epoch 99/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6366 - acc: 0.5855 - val_loss: 1.6353 - val_acc: 0.5864
Epoch 100/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6259 - acc: 0.5870 - val_loss: 1.6560 - val_acc: 0.5825
Epoch 101/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6228 - acc: 0.5863 - val_loss: 1.6491 - val_acc: 0.5838
Epoch 102/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6290 - acc: 0.5870 - val_loss: 1.6946 - val_acc: 0.5822
Epoch 103/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6355 - acc: 0.5856 - val_loss: 1.5911 - val_acc: 0.5932
Epoch 104/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6162 - acc: 0.5911 - val_loss: 1.6356 - val_acc: 0.5904
Epoch 105/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6281 - acc: 0.5877 - val_loss: 1.6008 - val_acc: 0.5960
Epoch 106/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6288 - acc: 0.5867 - val_loss: 1.6238 - val_acc: 0.5888
Epoch 107/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6302 - acc: 0.5872 - val_loss: 1.6605 - val_acc: 0.5834
Epoch 108/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6131 - acc: 0.5912 - val_loss: 1.6616 - val_acc: 0.5903
Epoch 109/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6221 - acc: 0.5909 - val_loss: 1.6561 - val_acc: 0.5809
Epoch 110/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6110 - acc: 0.5930 - val_loss: 1.6682 - val_acc: 0.5818
Epoch 111/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6188 - acc: 0.5882 - val_loss: 1.6319 - val_acc: 0.5876
Epoch 112/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6146 - acc: 0.5905 - val_loss: 1.6146 - val_acc: 0.5939
Epoch 113/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6053 - acc: 0.5941 - val_loss: 1.7054 - val_acc: 0.5780
Epoch 114/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6075 - acc: 0.5929 - val_loss: 1.7057 - val_acc: 0.5754
Epoch 115/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.5982 - acc: 0.5963 - val_loss: 1.6133 - val_acc: 0.5941
Epoch 116/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6094 - acc: 0.5927 - val_loss: 1.5968 - val_acc: 0.6018
Epoch 117/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6008 - acc: 0.5970 - val_loss: 1.6686 - val_acc: 0.5840
Epoch 118/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6101 - acc: 0.5953 - val_loss: 1.6253 - val_acc: 0.5902
Epoch 119/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.6035 - acc: 0.5948 - val_loss: 1.6581 - val_acc: 0.5897
Epoch 120/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6014 - acc: 0.5918 - val_loss: 1.6451 - val_acc: 0.5888
Epoch 121/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6153 - acc: 0.5918 - val_loss: 1.6821 - val_acc: 0.5825
Epoch 122/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6012 - acc: 0.5952 - val_loss: 1.6633 - val_acc: 0.5785
Epoch 123/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.5882 - acc: 0.5985 - val_loss: 1.6984 - val_acc: 0.5837
Epoch 124/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6072 - acc: 0.5938 - val_loss: 1.6262 - val_acc: 0.5967
Epoch 125/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5931 - acc: 0.5987 - val_loss: 1.6254 - val_acc: 0.5896
Epoch 126/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5915 - acc: 0.5978 - val_loss: 1.6321 - val_acc: 0.5914
Epoch 127/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.6004 - acc: 0.5949 - val_loss: 1.6580 - val_acc: 0.5805
Epoch 128/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5882 - acc: 0.6013 - val_loss: 1.6114 - val_acc: 0.5870
Epoch 129/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.5972 - acc: 0.5991 - val_loss: 1.6387 - val_acc: 0.5974
Epoch 130/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5843 - acc: 0.5987 - val_loss: 1.6286 - val_acc: 0.5917
Epoch 131/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5884 - acc: 0.5995 - val_loss: 1.6790 - val_acc: 0.5863
Epoch 132/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5924 - acc: 0.5987 - val_loss: 1.6863 - val_acc: 0.5866
Epoch 133/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5922 - acc: 0.5978 - val_loss: 1.6808 - val_acc: 0.5914
Epoch 134/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5980 - acc: 0.5974 - val_loss: 1.6373 - val_acc: 0.5934
Epoch 135/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.5847 - acc: 0.6014 - val_loss: 1.6420 - val_acc: 0.5985
Epoch 136/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5849 - acc: 0.6004 - val_loss: 1.6581 - val_acc: 0.5922
Epoch 137/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.5870 - acc: 0.5995 - val_loss: 1.6146 - val_acc: 0.6049
Epoch 138/139
1562/1562 [==============================] - 123s 78ms/step - loss: 1.5981 - acc: 0.5997 - val_loss: 1.6205 - val_acc: 0.6061
Epoch 139/139
1562/1562 [==============================] - 122s 78ms/step - loss: 1.5857 - acc: 0.6028 - val_loss: 1.6149 - val_acc: 0.5979
Elapsed time: 17041.68989276886 seconds.
